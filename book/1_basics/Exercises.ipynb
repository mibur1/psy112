{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <i class=\"fa-solid fa-dumbbell\"></i> Additional Exercises\n",
    "\n",
    "## Exercise 1: Psy111 Recap\n",
    "\n",
    "Remember the materials from last semester. Can you implement regression models using  `statsmodels` as well as the `sklearn` package? Which degree of polynomial will be most suited for the synthetic data?\n",
    "\n",
    "Please plot the resulting regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Generate synthetic data\n",
    "n_samples = 100\n",
    "X = np.linspace(-2, 2, n_samples).reshape(-1, 1)\n",
    "y = X**2 + np.random.normal(scale=0.5, size=X.shape)\n",
    "\n",
    "# TODO: Statsmodels\n",
    "...\n",
    "\n",
    "# TODO: Scikit-learn\n",
    "...\n",
    "\n",
    "# TODO: Plot the predictions\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Bias-variance Tradeoff\n",
    "\n",
    "To get a better understanding about the bias-variance tradeoff, we will fit polynomial regression models to synthetic data from a known function $y=sin(x)$.\n",
    "\n",
    "Please perform the following tasks:\n",
    "\n",
    "1. Visualize the data. Which model do you think would be optimal?\n",
    "2. Split the data into a training set (70%) and testing set (30%)\n",
    "3. Fit polynomial regression models for degrees 1 to 15\n",
    "4. Plot the errors against the model degrees\n",
    "\n",
    "*Hint: You can split the data with the `train_test_split()` function from `sklearn.model_selection`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(55)\n",
    "n_samples = 100\n",
    "X = np.linspace(0, 2*np.pi, n_samples).reshape(-1, 1)  # Reshape for sklearn\n",
    "y = np.sin(X) + np.random.normal(scale=0.5, size=X.shape)\n",
    "\n",
    "# 1. TODO: Visualize the data\n",
    "...\n",
    "\n",
    "# 2. TODO: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# 3. TODO: Fit polynomial regression models for degrees 1 to 15\n",
    "degrees = range(1, 16)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for degree in degrees:\n",
    "    ...\n",
    "\n",
    "# 4. TODO: Plot the training and testing errors against polynomial degree\n",
    "fig, ax = plt.subplots()\n",
    "...\n",
    "\n",
    "ax.set(xlabel=\"Polynomial Degree\", ylabel=\"Mean Squared Error\", title=\"Training vs. Testing Error\")\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Resampling Methods\n",
    "\n",
    "The dataset we are using for the exercise is the [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). It contains 20640 samples and 8 features. In this dataset, we have information regarding the demography (income, population, house occupancy) in the districts, the location of the districts (latitude, longitude), and general information regarding the house in the districts (number of rooms, number of bedrooms, age of the house). Since these statistics are at the granularity of the district, they corresponds to averages or medians.\n",
    "\n",
    "Familiarize yourself with the dataset by exploring the documentation and looking at the data. What are the features and target? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s have a quick look at the distribution of these features by plotting their histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 10), bins=30, edgecolor=\"black\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare the data for cross validation. This will require you to have a variable (e.g. `X`) for the features and a variable for the target (e.g. `y`).\n",
    "2. Set up a k-fold cross validation for a linear regression\n",
    "    - Choose an appropriate k\n",
    "    - Define the model\n",
    "    - Perform cross validation\n",
    "    - Use the mean squared error (MSE) to assess model performance\n",
    "\n",
    "*Hints:*\n",
    "- *For 1: You can achieve this by e.g. creating them from the DataFrame, or by using the `return_X_y` parameter on the [`fetch_california_housing()` function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)*\n",
    "- *For 2: You can use the `LinearRegession()` model from sklearn. You can further evaluate the model and specify the (negative) MSE as a performance measure in `cross_val_score()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare data\n",
    "X, y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "# TODO: Implement CV\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: LOOCV\n",
    "\n",
    "1. Use LOOCV and compare the average MSE\n",
    "2. Get the minimum and maximum MSE value. Discuss the range!\n",
    "3. Plot the MSE values in a histogram (thex range should be from 0 to 6)\n",
    "4. Calculate the median MSE and discuss if it might be a more appropriate measure than the mean\n",
    "\n",
    "*Hints*\n",
    "- *As we have 20640 observations this will probably take more than a minute to calculate. Feel free to subset the number of observations to e.g. 5000.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement LOOCV\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfc-multiverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
